# -*- coding: utf-8 -*-
"""Parkinsons.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jAv-Crh1n_UQhUelQwMkqZ_OvWlbFwvv
"""

#Importing the Dependencies
import numpy as np#importing numpy for array operations
import pandas as pd#importing pandas for dataframe management
from sklearn.preprocessing import StandardScaler#for standerdizing the data
from sklearn.model_selection import train_test_split#for splitting the data into training and testing data
from sklearn import svm#support vector machine for classification 
from sklearn.metrics import accuracy_score#for calculating the accuracy percentage to determine how accurate the model is

parkinsons_dataset=pd.read_csv('/content/parkinsons.csv')#reading the dataset 
parkinsons_dataset.head()#displaying the first 5 columns

parkinsons_dataset.shape#displaying the number of rows and columns in the dataset

parkinsons_dataset.describe()#displaying the statistical features of the values inside the dataset

parkinsons_dataset['status'].value_counts()#calculating the values of the status column
#1-->Parkinsons Positive
#0-->Parkinsons Negative

#parkinsons_dataset.drop(columns='name',axis=1,inplace=True)
parkinsons_dataset.head()
#Dropping the name column as it plays no role

parkinsons_dataset.shape#New dataset shape

X=parkinsons_dataset.drop(columns='status',axis=1)#keeping all the values of the dataset except the labels column
Y=parkinsons_dataset['status']#storing the status column from the dataset 
X.drop(columns='name',axis=1,inplace=True)#Dropping the name column again
print(X)#checking if the name column got dropped

#Most of the data are different than the others and hence we use Standard Scaler to standerdize the data 
scaler=StandardScaler()
scaler.fit(X)
standerdized_data=scaler.transform(X)
print(standerdized_data)

#Splitting the data into training and testing set
x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=0)
print(X.shape,x_train.shape,x_test.shape)

#Using the support vector machine classifier
classifier=svm.SVC(kernel='linear')
classifier.fit(x_train,y_train)

#Prediction on the training dataset 
predict1=classifier.predict(x_train)

#Prediction on the testing dataset 
predict2=classifier.predict(x_test)

#Accuracy score of the model on the predictions on the training and testing datasets
train_score=accuracy_score(predict1,y_train)
test_score=accuracy_score(predict2,y_test)

print("Accuracy of Training Data Prediction ",train_score)
print("Accuracy of Testing Data Prediction ",test_score)

#Making a predictive system
input_data=(119.99200,157.30200,74.99700,0.00784,0.00007,0.00370,0.00554,0.01109,0.04374,0.42600,0.02182,0.03130,0.02971,0.06545,0.02211,21.03300,0.414783,0.815285,-4.813031,0.266482,2.301442,0.284654)
#This is where we will be taking the input
input_data_as_numpy=np.asarray(input_data)#Transforming the input data into a array for ease of access
input_data_reshaped=input_data_as_numpy.reshape(1,-1)#reshaping the data
prediction=classifier.predict(input_data_reshaped)
print(prediction)

#Using a simple if and else systen to display the output
if(prediction[0]==1):
  print('Patient has a Parkinsons and needs further medical examination')

else:
  print('Patient does not have Parkinsons')

